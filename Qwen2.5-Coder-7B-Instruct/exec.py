# -*- coding: utf-8 -*-
"""ES2PT2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/141DweNQVlf0vlqRnBpX4HgIUmUg8XtnH
"""

!pip install -q -U torch transformers accelerate bitsandbytes

import torch
from transformers import pipeline, BitsAndBytesConfig

model_id = "Qwen/Qwen2.5-Coder-7B-Instruct"

# Configuração para carregar em 4-bits
bnb_config = BitsAndBytesConfig(
    load_in_4bit=True,
    bnb_4bit_use_double_quant=True,
    bnb_4bit_quant_type="nf4",
    bnb_4bit_compute_dtype=torch.bfloat16
)

print(f"Iniciando download e carregamento do {model_id}...")

pipe = pipeline(
    "text-generation",
    model=model_id,
    model_kwargs={"quantization_config": bnb_config},
    device_map="auto",
)

import torch
import gc

# Força o Python a liberar variáveis não usadas
gc.collect()

# Força o PyTorch a limpar o cache da GPU
torch.cuda.empty_cache()

print("Memória da GPU limpa!")

# Copiar e colar aqui o conteúdo do CONTRIBUTING.md, GOVERNANCE.md
# ou a seção do README que explica como contribuir.
documentacao_projeto = """
[SUBSTITUIR POR DOCUMENTO QUE SERÁ ANALISADO]
""" ## [:15000] ## Pode ser necessário remover o comentário anterior caso o modelo consuma muita memória RAM com o arquivo enviado, para contornar isso, limitamos até onde o modelo irá ler

messages = [
    {
        "role": "system",
        "content": "Você é um Engenheiro de Software Sênior especialista em DevOps, Governança de TI e Processos de Software Open Source."
    },
    {
        "role": "user",
        "content": f"""
        Com base EXCLUSIVAMENTE na documentação fornecida abaixo, analise a governança do projeto e responda em Português do Brasil:

        1. **Estratégia de Releases**: Identifique o modelo (ex: Rapid Releases, Release Train, LTS + Current). Explique como você chegou a essa conclusão citando trechos do texto.

        2. **Modelo de Fluxo de Trabalho (Branching Model)**: Identifique como o código é organizado (ex: Gitflow, GitHub Flow, Trunk-based). Explique a estrutura de branches mencionada no texto (ex: main, develop, feature branches).

        ---
        DOCUMENTAÇÃO PARA ANÁLISE:
        {documentacao_projeto}
        ---
        """
    },
]

print("\n--- GERANDO ANÁLISE (Aguarde alguns segundos) ---\n")

outputs = pipe(
    messages,
    max_new_tokens=1024, # Permite respostas longas e detalhadas
    temperature=0.1,     # Baixa criatividade para garantir precisão técnica
    do_sample=True,
)

# Mostra apenas a resposta final e limpa
print(outputs[0]["generated_text"][-1]["content"])